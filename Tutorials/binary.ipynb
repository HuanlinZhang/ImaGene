{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial for binary classification using _ImaGene_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a short tutorial to learn the basic usage of _ImaGene_ which contains a series of objects in _python_ to interact with _keras_ , one of the most popular used packages for deep learning.\n",
    "\n",
    "In this example our aim is to predict whether a given locus is under positive from population genomic data. Therefore, we will use _ImaGene_ to perform a binary classification and we will use the classic example of positive selection for lactase persistence. \n",
    "\n",
    "The C/T(-13910) variant, or rs4988235, is located on chromosome 2 in the _MCM6_ gene but influences the lactase _LCT_ gene. This SNP is associated with the primary haplotype associated with lactose intolerance in European populations. \n",
    "In these populations, the common T allele is associated with lactase persistence. Individuals who are homozygous for C allele are likely to be lactose intolerant. \n",
    "We extracted SNP information from a region of 80k base pairs around the target variant rs4988235 from the 1000 Genomes Project data for all unrelated individuals of CEU population (of European descent).\n",
    "The data is in the form of a VCF file.\n",
    "\n",
    "In this tutorial, you will learn how to:\n",
    "1. read data from VCF file and store it in an object from _ImaGene_ ,\n",
    "2. run and process simulations to be used for training the neural network,\n",
    "3. implement, train and evaluate the neural network,\n",
    "4. deploy the trained network on your genomic data of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the necessary modules in _python_ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gzip\n",
    "import _pickle as pickle\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "import skimage.transform\n",
    "from keras import models, layers, activations, optimizers, regularizers\n",
    "from keras.utils import plot_model\n",
    "from keras.models import load_model\n",
    "\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pydot # optional, but required by keras to plot the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load _ImaGene_ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../ImaGene.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial has been tested with:\n",
    "* python 3.6.9\n",
    "* numpy 1.17.4\n",
    "* scipy 1.3.1 \n",
    "* keras 2.2.4\n",
    "* tensorflow 1.15.0\n",
    "* scikit-image 0.15.0\n",
    "* scikit-learn 0.21.3\n",
    "* matplotlib 3.1.1\n",
    "* pydot 1.4.1 \n",
    "\n",
    "and we recommend creating a conda environment with these packages and versions.\n",
    "For instance,\n",
    "`conda create -n ImaGene python=3.6 tensorflow=1.15`\n",
    "which can be activated with \n",
    "`conda activate ImaGene` \n",
    "and deactivated with\n",
    "`conda deactivate`.\n",
    "We are currently working on updating _ImaGene_ to make it compatible with `tensorflow=2.0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store the information of the genomic data into an _ImaFile_ object where we specify the name of the VCF file and the number of samples (i.e. the number of chromosomal copies, twice the number of individuals for a diploid organism).\n",
    "The latter parameter is not strictly necessary but it is useful to check whether the VCF we are analysing contains the data that we expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_LCT = ImaFile(nr_samples=198, VCF_file_name='LCT.CEU.vcf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an _ImaGene_ object by reading the VCF file and generating a matrix of haplotypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_LCT = file_LCT.read_VCF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a look at the data stored in this object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An object of 1 image(s)\n",
      "Rows: min 198, max 198, mean 198.000000, std 0.000000\n",
      "Columns: min 2200, max 2200, mean 2200.000000, std 0.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_LCT.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene_LCT.majorminor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_LCT.filter_freq(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_LCT.sort('rows_freq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_LCT.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_LCT.plot(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "subprocess.call(\"bash ../generate_dataset.sh params_binary.txt\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import _pickle as pickle\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "import skimage.transform\n",
    "from keras import models, layers, activations, optimizers, regularizers\n",
    "from keras.utils import plot_model\n",
    "from keras.models import load_model\n",
    "\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pydot # optional, but required by keras to plot the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to generate training and testing datasets. This is accomplished using _msms_. An example on how to do this is given in the script below. This script will split the simulations into different batches to later perform training with a \"simulation-on-the-fly\" approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../ImaGene.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform the first iteration of training.\n",
    "\n",
    "To do that, the first thing to do is to read the first batch of simulations and store them into an _ImaFile_ object. We assume we have 128 samples (haplotypes) using a 3-epoch demographic model for Europeans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile = ImaFile(simulations_folder='/home/mfumagal/Downloads/ImaGene/Simulations1', nr_samples=128, model_name='Marth-3epoch-CEU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we populate an _ImaGene_ object by selection the variabile we want to estimate/predict ('selection_coeff_hetero') and how many data points per class we wish to retain. As a quick example, we will use only 2000 data points per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygene = myfile.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=20, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a look at the data stored in this object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygene.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we have 10000 images in this object. Recall that with the first line we simulated 5 classes and retain 2000 data points for each class. All images have 128 rows as expected, as this represents the number of simulated haplotypes. However, images have different number of columns, ranging from 110 to 422 with an average value of around 257. The number of columns represents the number of polymorphic sites and fixed derived alleles in a _msms_ file. This number may vary from simulated image to another.\n",
    "\n",
    "We can also check the sample allele frequency for the selected allele. recall that we imposed selection to be acting in the middle of the region. Therefore, the targeted allele will be in position '0.5' in the _msms_ file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = calculate_allele_frequency(mygene, 0.5)\n",
    "plt.scatter(mygene.targets, freqs, marker='o')\n",
    "plt.xlabel('Selection coefficient')\n",
    "plt.ylabel('Allele frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the current allele frequency for the targeted allele (on the y-axis) tends to increase for increasing selection coefficient (on the x-axis).\n",
    "\n",
    "Next, _ImaGene_ provides functionalities to manipulate our object. Specifically we can do the following:\n",
    "* convert ancestral/derived to major/minor allele polarisation\n",
    "* filter out columns based on a minimum allele frequency (e.g. 0.01)\n",
    "* sorting rows and columns by frequency (or distance from the most frequent entry)\n",
    "* resize rows and columns (e.g. to 128x128)\n",
    "\n",
    "For instance, the options above could be achieved with the following lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygene.majorminor()\n",
    "mygene.filter_freq(0.01)\n",
    "mygene.sort('rows_freq')\n",
    "mygene.sort('cols_freq')\n",
    "mygene.resize((128, 128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can explore all different options that can be used from their help pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?mygene.sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?mygene.resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the data manipulation is done, we have to convert images to proper _numpy_ float matrices. The following line will do the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygene.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this '.convert' method allows you to normalise the data too, according to its help page. You can also suppress any messages on the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?mygene.convert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an illustration, let's plot one image per class. We can also check the new data dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sel in mygene.classes:\n",
    "    print(sel)\n",
    "    mygene.plot(np.where(mygene.targets == sel)[0][0])\n",
    "mygene.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's suppose that we want to do a simple binary classification. This means that we only want to consider 2 classes. For doing that, first we need to set '.classes' to the desired values and then we need to take a subset of the data corresponding to the desired classes only.\n",
    "\n",
    "We can achieve these steps with the following lines with, as an illustration,  classes (i.e. selection coefficients) of 0 and 300 (in 2Ne units)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygene.classes = np.array([0,300])\n",
    "classes_idx = get_index_classes(mygene.targets, mygene.classes)\n",
    "len(classes_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we now have 4000 data points, as expected. Finally, let's take the corresponding subset of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygene.subset(classes_idx)\n",
    "mygene.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have an object of 4000 data points (images). \n",
    "\n",
    "The next thing to do is very important. We need to randomly shuffle our retained images before using them for training our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_idx = get_index_random(mygene)\n",
    "mygene.subset(rnd_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment our targets represent the 2 possible classes. However, since we are doing a binary classification, we need to vectorise them as required by _keras_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygene.targets = to_binary(mygene.targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object is now ready to be used for the classification!\n",
    "You can save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygene.save(file='Data/mygene.binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to load an _ImaGene_ object you can use the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygene = load_imagene(file='Data/mygene.binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data is ready, we can build our network.\n",
    "Specifically, we can build a model in _keras_ with convolutional, pooling and dense layers.\n",
    "In this example we have 3 layers of 2D convolutions and pooling followed by a fully-connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "                    layers.Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.005, l2=0.005), padding='valid', input_shape=mygene.data.shape[1:4]),\n",
    "                    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "                    layers.Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.005, l2=0.005), padding='valid'),\n",
    "                    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "                    layers.Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.005, l2=0.005), padding='valid'),\n",
    "                    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "                    layers.Flatten(),\n",
    "                    layers.Dense(units=64, activation='relu'),\n",
    "                    layers.Dense(units=1, activation='sigmoid')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's compile our _keras_ model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a summary of the model and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "plot_model(model, 'Data/net.binary.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready for doing the training on this first batch of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.fit(mygene.data, mygene.targets, batch_size=32, epochs=1, verbose=1, validation_split=0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that you can save a _keras_ model with `model.save('net.h5')`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can initialise a network object _ImaNet_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mynet = ImaNet(name='[C32+P]x3+D64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can keep track of scores (loss and accuracy) across iterations with '.update_scores'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mynet.update_scores(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can repeat the whole procedure described above using all remaning batches of data, leaving the last one for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "while i < 10:\n",
    "\n",
    "    print(i)\n",
    "    \n",
    "    myfile = ImaFile(simulations_folder='/home/mfumagal/Data/ImaGene/Binary/Simulations' + str(i), nr_samples=128, model_name='Marth-3epoch-CEU')\n",
    "    mygene = myfile.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=2000)\n",
    "\n",
    "    mygene.majorminor()\n",
    "    mygene.filter_freq(0.01)\n",
    "    mygene.sort('rows_freq')\n",
    "    mygene.sort('cols_freq')\n",
    "    mygene.resize((128, 128))\n",
    "    mygene.convert(verbose=False)\n",
    "\n",
    "    mygene.classes = np.array([0,300])\n",
    "    mygene.subset(get_index_classes(mygene.targets, mygene.classes))\n",
    "    mygene.subset(get_index_random(mygene))\n",
    "\n",
    "    mygene.targets = to_binary(mygene.targets)\n",
    "     \n",
    "    score = model.fit(mygene.data, mygene.targets, batch_size=32, epochs=1, verbose=1, validation_split=0.10)\n",
    "    mynet.update_scores(score)\n",
    "   \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot loss and validation accuracy during the training to check, for instance, for overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mynet.plot_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save (and/or load) the final trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Data/model.binary.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('Data/model.binary.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also save the network itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mynet.save('Data/mynet.binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we evaluate the training on the testing dataset, i.e. the last batch of simulated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 10\n",
    "myfile = ImaFile(simulations_folder='/home/mfumagal/Data/ImaGene/Binary/Simulations' + str(i), nr_samples=128, model_name='Marth-3epoch-CEU')\n",
    "mygene_test = myfile.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=2000)\n",
    "\n",
    "mygene_test.majorminor()\n",
    "mygene_test.filter_freq(0.01)\n",
    "mygene_test.sort('rows_freq')\n",
    "mygene_test.sort('cols_freq')\n",
    "mygene_test.resize((128, 128))\n",
    "mygene_test.convert(verbose=False)\n",
    "\n",
    "mygene_test.classes = np.array([0,300])\n",
    "classes_idx = get_index_classes(mygene_test.targets, mygene_test.classes)\n",
    "mygene_test.subset(classes_idx)\n",
    "rnd_idx = get_index_random(mygene_test)\n",
    "mygene_test.subset(rnd_idx)\n",
    "\n",
    "mygene_test.targets = to_binary(mygene_test.targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's report loss and accuracy on the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mynet.test = model.evaluate(mygene_test.data, mygene_test.targets, batch_size=None, verbose=0)\n",
    "print(mynet.test) # it will report [loss, accuracy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a binary or multiclass classification, it is convenient to plot the confusion matrix after predicting the responses from the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mynet.predict(mygene_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mynet.plot_cm(mygene_test.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the estimation of continuous variabiles, we can produce a scatter plot with `mynet.plot_scatter()`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
